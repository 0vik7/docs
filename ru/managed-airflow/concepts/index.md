---
title: "Взаимосвязь ресурсов сервиса {{ maf-full-name }}"
description: "{{ AF }} — это платформа с открытым исходным кодом для создания, планирования и мониторинга пакетно ориентированных воркфлоу. Сервис {{ maf-full-name }} помогает разворачивать и поддерживать кластеры серверов {{ AF }} в инфраструктуре {{ yandex-cloud }}."
---

# Взаимосвязь ресурсов в {{ maf-name }}

Сервис {{ maf-name }} помогает разворачивать и поддерживать кластеры серверов [{{ AF }}](https://airflow.apache.org/) в инфраструктуре {{ yandex-cloud }}.


Сервис находится на стадии [Preview](../../overview/concepts/launch-stages.md). Доступ к сервису предоставляется по запросу.


## Об {{ AF }} {#about-the-service}

{{ AF }} — это платформа с открытым исходным кодом для создания, планирования и мониторинга пакетно ориентированных _воркфлоу_. Воркфлоу определяет взаимосвязь задач и последовательность их выполнения и представлен в виде направленного ациклического графа — DAG (Directed Acyclic Graph). Направленные ациклические графы в {{ AF }} можно применять для автоматизации и запуска по расписанию любых процессов, например [обработки данных в {{ SPRK }}](../../data-proc/tutorials/spark-job-basics.md).

В {{ AF }} используется подход <q>Workflows as code</q>. Он подразумевает, что каждый воркфлоу реализуется с помощью скрипта на Python. Файл с таким скриптом называется _DAG-файлом_. В нем описываются задачи, расписание их запуска и зависимости между ними. Такой подход позволяет хранить воркфлоу в системе контроля версий, запускать тесты и подключать нужные технологии для воркфлоу.

{{ AF }} не применяется для потоковой и непрерывной обработки данных. Если она нужна, можно создать решение на основе сервиса [{{ mkf-full-name }}](../../managed-kafka/index.yaml).

Более подробная информация приведена в документации [{{ AF }}](https://airflow.apache.org/docs/apache-airflow/stable/#).

## Кластер {{ maf-name }} {#cluster}

Основная сущность, которой оперирует сервис {{ maf-name }}, — _кластер_. В нем развернуты [компоненты {{ AF }}](#components). Ресурсы кластера могут находиться в разных зонах доступности. Подробнее о географии {{ yandex-cloud }} см. в разделе [Обзор платформы](../../overview/concepts/geo-scope.md).

Воркфлоу, запущенный в кластере, может обращаться к любому ресурсу {{ yandex-cloud }} в пределах облачной сети, в которой находится кластер. Например, воркфлоу может отправлять запросы виртуальной машине {{ yandex-cloud }} или кластеру управляемой базы данных (БД). Так можно построить воркфлоу с использованием нескольких ресурсов. Например, воркфлоу забирает данные из одной БД, обрабатывает их и отправляет в другую БД или [{{ dataproc-full-name }}](../../data-proc/index.yaml).

## Основные компоненты {{ maf-name }} {#components}

Архитектура сервиса и его основные компоненты представлены на схеме:

![architecture](../../_assets/managed-airflow/architecture.svg)

Компоненты {{ maf-name }}:

* _Веб-сервер_ — сервер в {{ yandex-cloud }}, на котором размещается экземпляр {{ AF }}. Веб-сервер получает команды от пользователей, отправленные через веб-интерфейс {{ AF }}, проверяет, запускает и отлаживает Python-скрипты в DAG-файлах.

   Подробнее о работе с веб-интерфейсом см. в [документации {{ AF }}](https://airflow.apache.org/docs/apache-airflow/stable/ui.html).

* _Планировщик_ — сервер в {{ yandex-cloud }}, который управляет расписанием запуска задач. Планировщик получает информацию о расписании из DAG-файлов. По этому расписанию он сообщает воркерам, что пора запустить DAG-файл.

* _Воркеры_ — исполнители задач, указанных в DAG-файлах. Воркеры выполняют задачи по расписанию от планировщика.

* [_Triggerer_](#triggerer) — служба, которая освобождает воркер в случае его простоя при выполнении задания с длительным ожиданием события (опциональный компонент).

* _Хранилище DAG-файлов_ — [бакет {{ objstorage-full-name }}](../../storage/concepts/bucket.md), в котором хранятся DAG-файлы. К этому хранилищу имеют доступ веб-сервер, планировщик, воркеры и Triggerer.

Схема взаимодействия компонентов приводится в [описании архитектуры {{ AF }}](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/overview.html).

Чтобы обеспечить отказоустойчивость и повысить производительность, веб-серверы, планировщики и Triggerer могут существовать в нескольких экземплярах. Их количество определяется во время создания кластера.

Для воркеров задается минимальное и максимальное количество экземпляров также при создании кластера. Их количество будет масштабироваться динамически.

## Triggerer {#triggerer}

Служба Triggerer позволяет сократить время простоя воркеров.

В графах DAG могут быть задачи, которые отправляют запрос во внешнюю систему (например, кластер {{ SPRK }}) и ожидают ответ от нее в течение некоторого времени. Если использовать [стандартные операторы](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/operators.html), задача занимает воркер, пока ожидает ответа. В результате воркер простаивает. Когда такое происходит с большим количеством воркеров, образуются очереди задач, и скорость их запуска и выполнения снижается.

Избежать такой ситуации позволяют _отложенные операторы_ (deferrable operators). С их помощью задача приостанавливается, освобождается воркер, и опрос внешней системы выделяется в отдельный процесс — _триггер_ (trigger). Все триггеры независимо друг от друга (асинхронно) обрабатываются службой Triggerer, для которой в кластере выделены отдельные ресурсы. При получении ответа от внешней системы триггер срабатывает, и планировщик возвращает задачу воркеру.

Процесс работы со службой Triggerer представлен на схеме:

![triggerer](../../_assets/managed-airflow/triggerer.svg)

Подробнее об отложенных операторах, триггерах и службе Triggerer см. в документации [{{ AF }}](https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/deferring.html#deferrable-operators-triggers).
